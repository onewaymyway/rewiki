{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OrzWiki _ Main _ HomePage.htm', 'OrzWiki _ Main _ HomePage_files', 'OrzWiki _ Other _ Ideas.htm', 'OrzWiki _ Other _ Ideas_files', 'OrzWiki _ SNS _ 推荐引擎.htm', 'OrzWiki _ SNS _ 推荐引擎_files', 'OrzWiki _ SNS _ 网站相关.htm', 'OrzWiki _ SNS _ 网站相关_files', 'OrzWiki _ 学习 _ AR.htm', 'OrzWiki _ 学习 _ AR_files', 'OrzWiki _ 学习 _ As3.htm', 'OrzWiki _ 学习 _ As3_files', 'OrzWiki _ 学习 _ IDE.htm', 'OrzWiki _ 学习 _ IDE_files', 'OrzWiki _ 学习 _ Js.html', 'OrzWiki _ 学习 _ Js_files', 'OrzWiki _ 学习 _ Python.htm', 'OrzWiki _ 学习 _ Python_files', 'OrzWiki _ 学习 _ TodoList.htm', 'OrzWiki _ 学习 _ TodoList_files', 'OrzWiki _ 学习 _ 产品Amp运营.htm', 'OrzWiki _ 学习 _ 产品Amp运营_files', 'OrzWiki _ 学习 _ 公开课forDear.htm', 'OrzWiki _ 学习 _ 公开课forDear_files', 'OrzWiki _ 学习 _ 动画相关.htm', 'OrzWiki _ 学习 _ 动画相关_files', 'OrzWiki _ 学习 _ 安全相关.htm', 'OrzWiki _ 学习 _ 安全相关_files', 'OrzWiki _ 学习 _ 开放平台们.htm', 'OrzWiki _ 学习 _ 开放平台们_files', 'OrzWiki _ 学习 _ 数据分析.htm', 'OrzWiki _ 学习 _ 数据分析_files', 'OrzWiki _ 学习 _ 算法.htm', 'OrzWiki _ 学习 _ 算法_files', 'OrzWiki _ 学习 _ 语法分析.htm', 'OrzWiki _ 学习 _ 语法分析_files', 'OrzWiki _ 学习 _ 调试工具.htm', 'OrzWiki _ 学习 _ 调试工具_files', 'OrzWiki _ 学习 _ 量化交易.htm', 'OrzWiki _ 学习 _ 量化交易.html', 'OrzWiki _ 学习 _ 量化交易_files', 'OrzWiki _ 学习 _ 项目管理工具.htm', 'OrzWiki _ 学习 _ 项目管理工具_files', 'OrzWiki _ 工具 _ Chrome.htm', 'OrzWiki _ 工具 _ Chrome_files', 'OrzWiki _ 工具 _ 导航导航.htm', 'OrzWiki _ 工具 _ 导航导航_files', 'OrzWiki _ 生活 _ 动漫.htm', 'OrzWiki _ 生活 _ 动漫_files', 'OrzWiki _ 生活 _ 域名.htm', 'OrzWiki _ 生活 _ 域名_files', 'OrzWiki _ 生活 _ 心理社会星座.htm', 'OrzWiki _ 生活 _ 心理社会星座_files', 'OrzWiki _ 生活 _ 电影.htm', 'OrzWiki _ 生活 _ 电影_files', 'OrzWiki _ 生活 _ 读书.htm', 'OrzWiki _ 生活 _ 读书_files', 'OrzWiki _ 生活 _ 追剧.htm', 'OrzWiki _ 生活 _ 追剧_files', 'OrzWiki _ 生活 _ 音乐.htm', 'OrzWiki _ 生活 _ 音乐_files']\n",
      "group: Main\n",
      "title: HomePage\n",
      "维护wiki\n",
      "\n",
      "做一个浏览器壳\n",
      "\n",
      "做一个内容网站\n",
      "\n",
      "做一个导航站\n",
      "\n",
      "做一个任务分析的工具\n",
      "\n",
      "做一个主动的网站\n",
      "\n",
      "做一个互联网地图站\n",
      "\n",
      "量化交易研究\n",
      "\n",
      "强化学习研究\n",
      "\n",
      "学习Python服务器编程\n",
      "\n",
      "chrome浏览器插件开发\n",
      "\n",
      "连接JoinQuant研究的python库\n",
      "\n",
      "group: Other\n",
      "title: Ideas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file D:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "通过图片像素进行战斗\n",
      "\n",
      "group: SNS\n",
      "title: 推荐引擎\n",
      "group: SNS\n",
      "title: 网站相关\n",
      "group: 学习\n",
      "title: AR\n",
      "group: 学习\n",
      "title: As3\n",
      "AMF3协议中文版\n",
      "\n",
      "swf_file_format_spec_v10.pdf\n",
      "\n",
      "flashplatform_optimizing_content\n",
      "\n",
      "Away3D.3.6.Cookbook\n",
      "\n",
      "\n",
      "\n",
      "group: 学习\n",
      "title: IDE\n",
      "group: 学习\n",
      "title: Js\n",
      " chrome://inspect/#service-workers\n",
      "\n",
      " chrome://serviceworker-internals/\n",
      "\n",
      "《Effective JavaScript》\n",
      "\n",
      "《JavaScript 权威指南》\n",
      "\n",
      "Apress.Beginning.HTML5.Games.with.CreateJS\n",
      "\n",
      "Beginning WebGL for HTML5\n",
      "\n",
      "Game Development with Three.js\n",
      "\n",
      "Game Engine Architecture(游戏引擎架构)\n",
      "\n",
      "Game.Physics.Engine.Development\n",
      "\n",
      "WebGL Programming Guide\n",
      "\n",
      "JS面向对象教程\n",
      "\n",
      "group: 学习\n",
      "title: Python\n",
      "group: 学习\n",
      "title: TodoList\n",
      "维护wiki\n",
      "\n",
      "做一个浏览器壳\n",
      "\n",
      "做一个内容网站\n",
      "\n",
      "做一个导航站\n",
      "\n",
      "做一个任务分析的工具\n",
      "\n",
      "做一个主动的网站\n",
      "\n",
      "做一个互联网地图站\n",
      "\n",
      "量化交易研究\n",
      "\n",
      "强化学习研究\n",
      "\n",
      "学习Python服务器编程\n",
      "\n",
      "chrome浏览器插件开发\n",
      "\n",
      "连接JoinQuant研究的python库\n",
      "\n",
      "group: 学习\n",
      "title: 产品Amp运营\n",
      "group: 学习\n",
      "title: 公开课forDear\n",
      "group: 学习\n",
      "title: 动画相关\n",
      "group: 学习\n",
      "title: 安全相关\n",
      "Proxmark3\n",
      "\n",
      "group: 学习\n",
      "title: 开放平台们\n",
      "group: 学习\n",
      "title: 数据分析\n",
      "group: 学习\n",
      "title: 算法\n",
      "矩阵分析与应用\n",
      "\n",
      "图论与网络流理论\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "group: 学习\n",
      "title: 语法分析\n",
      "Language.Implementation.Patterns\n",
      "\n",
      "Pragmatic.The Definitive ANTLR 4 Reference.2013\n",
      "\n",
      "编译原理及实践\n",
      "\n",
      "group: 学习\n",
      "title: 调试工具\n",
      "group: 学习\n",
      "title: 量化交易\n",
      "group: 学习\n",
      "title: 量化交易\n",
      "group: 学习\n",
      "title: 项目管理工具\n",
      "group: 工具\n",
      "title: Chrome\n",
      "group: 工具\n",
      "title: 导航导航\n",
      "group: 生活\n",
      "title: 动漫\n",
      "group: 生活\n",
      "title: 域名\n",
      "u0game.com|幽灵游戏\n",
      "\n",
      "0sgame.com|0秒游戏\n",
      "\n",
      "87d4.com|霸气屌丝\n",
      "\n",
      "9k123.com|9k123\n",
      "\n",
      "9iyo.com|就爱游\n",
      "\n",
      "kxv5.com|开心威武\n",
      "\n",
      "i9k9k.com|i9k9k\n",
      "\n",
      "i8k8k.com|i8k8k\n",
      "\n",
      "i2b2b.com|i2b2b\n",
      "\n",
      "i3x3x.com|i3x3x\n",
      "\n",
      "3k3k8.com|3k3k8\n",
      "\n",
      "zizi8.com|zizi8\n",
      "\n",
      "9k9kwan.com|9k9kwan\n",
      "\n",
      "8kle.com|8k乐\n",
      "\n",
      "4vcity.com|4维city\n",
      "\n",
      "z8city.com|z8city\n",
      "\n",
      "v5town.com|威武town\n",
      "\n",
      "if87.com|如果霸气\n",
      "\n",
      "ifv5.com|如果威武\n",
      "\n",
      "99dese.com|99得瑟\n",
      "\n",
      "v5dese.com|威武得瑟\n",
      "\n",
      "94dese.com|就是得瑟\n",
      "\n",
      "87liu.com|876\n",
      "\n",
      "876wu.com|8765\n",
      "\n",
      "0knet.com|0k网\n",
      "\n",
      "0kweb.com|0k网\n",
      "\n",
      "g9web.com|居久网\n",
      "\n",
      "419cafe.com|一夜情cafe\n",
      "\n",
      "7kpub.com|7kpub\n",
      "\n",
      "34pub.com|34pub\n",
      "\n",
      "5ipub.com|我爱pub\n",
      "\n",
      "k5cafe.com|k5cafe\n",
      "\n",
      "9kcafe.com|9kcafe\n",
      "\n",
      "7kcafe.com|7kcafe\n",
      "\n",
      "kfcafe.com|开房cafe\n",
      "\n",
      "putaput.com|put a put\n",
      "\n",
      "8of24.com|一天八小时\n",
      "\n",
      "v5map.com|威武地图\n",
      "\n",
      "fingerbar.com|手指吧\n",
      "\n",
      "fingerpub.com|手指俱乐部\n",
      "\n",
      "fingeritch.com|手指痒\n",
      "\n",
      "fingernuts.com|手指疯子\n",
      "\n",
      "fingergeek.com|手指极客\n",
      "\n",
      "handitch.com|手痒\n",
      "\n",
      "heartitch.com|心痒\n",
      "\n",
      "fingerquake.com|手指震颤\n",
      "\n",
      "butfame.com|butfame\n",
      "\n",
      "butasy.com|butasy.com\n",
      "\n",
      "hitTheFront.com|hitTheFront.com\n",
      "\n",
      "roburstmoney|roburstmoney\n",
      "\n",
      "group: 生活\n",
      "title: 心理社会星座\n",
      "group: 生活\n",
      "title: 电影\n",
      "海上钢琴师\n",
      "\n",
      "死亡诗社\n",
      "\n",
      "死亡实验\n",
      "\n",
      "上帝保佑美利坚\n",
      "\n",
      "赌博默示录\n",
      "\n",
      "我在一家黑公司上班，已经快撑不下去了\n",
      "\n",
      "惊天魔盗团\n",
      "\n",
      "欺诈游戏\n",
      "\n",
      "死亡笔记\n",
      "\n",
      "拉面女孩\n",
      "\n",
      "黑萝莉与白萝莉\n",
      "\n",
      "星空\n",
      "\n",
      "等一个人咖啡\n",
      "\n",
      "早春\n",
      "\n",
      "利蓝的美国\n",
      "\n",
      "弯曲吧！汤匙\n",
      "\n",
      "东京朋友\n",
      "\n",
      "一日人生\n",
      "\n",
      "极盗者\n",
      "\n",
      "金氏漂流记\n",
      "\n",
      "爱的曝光\n",
      "\n",
      "越光宝盒\n",
      "\n",
      "我的PS搭档\n",
      "\n",
      "完美搭档\n",
      "\n",
      "前度\n",
      "\n",
      "爱妹物语\n",
      "\n",
      "咖喱辣妹\n",
      "\n",
      "纯情漫画\n",
      "\n",
      "宠物情人\n",
      "\n",
      "婚礼绯闻\n",
      "\n",
      "脑海中的橡皮擦\n",
      "\n",
      "人间中毒\n",
      "\n",
      "恋爱不可承受之轻\n",
      "\n",
      "夜之女王\n",
      "\n",
      "一生一世\n",
      "\n",
      "挪威的森林\n",
      "\n",
      "爱疯三次元\n",
      "\n",
      "超市夜未眠\n",
      "\n",
      "时代精神\n",
      "\n",
      "财富理论\n",
      "\n",
      "学校的地下网站\n",
      "\n",
      "九死\n",
      "\n",
      "狗镇\n",
      "\n",
      "世界再见\n",
      "\n",
      "十二公民\n",
      "\n",
      "爱情和香烟\n",
      "\n",
      "2077日本锁国\n",
      "\n",
      "group: 生活\n",
      "title: 读书\n",
      "科幻世界\n",
      "\n",
      "group: 生活\n",
      "title: 追剧\n",
      "新闻编辑室\n",
      "\n",
      "世界奇妙物语\n",
      "\n",
      "天蝎计划\n",
      "\n",
      "黑名单\n",
      "\n",
      "我们都是超能力者\n",
      "\n",
      "欺诈游戏\n",
      "\n",
      "DoctorX\n",
      "\n",
      "当按下开关时\n",
      "\n",
      "野猪大改造\n",
      "\n",
      "还以为要死了\n",
      "\n",
      "大川端侦探社\n",
      "\n",
      "最好的选择TAXI\n",
      "\n",
      "双螺旋\n",
      "\n",
      "超能力\n",
      "\n",
      "生活大爆炸\n",
      "\n",
      "夜班医生\n",
      "\n",
      "尼克病院\n",
      "\n",
      "黑帆\n",
      "\n",
      "迷失\n",
      "\n",
      "网络犯罪调查\n",
      "\n",
      "西部世界\n",
      "\n",
      "group: 生活\n",
      "title: 音乐\n",
      "朴树\n",
      "\n",
      "周杰伦\n",
      "\n",
      "许巍\n",
      "\n",
      "Michael Jackson\n",
      "\n",
      "《困兽之斗》周杰伦\n",
      "\n",
      "《活着》朴树\n",
      "\n",
      "《曾经的你》许巍\n",
      "\n",
      "《heal the world》Michael Jackson\n",
      "\n",
      "《那女孩对我说》黄义达\n",
      "\n",
      "《不够成熟》By2\n",
      "\n",
      "《遇见》孙燕姿\n",
      "\n",
      "《In the end》Linkin Park\n",
      "\n",
      "《Right Here waiting》Richard Noel Marx\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "\n",
    "def readXml(filepath):\n",
    "    return BeautifulSoup(open(filepath,encoding=\"utf8\"))\n",
    "\n",
    "def traceChildren(children):\n",
    "    for child in children:\n",
    "        print(\"~~~\",child)\n",
    "def traceObj(obj):\n",
    "    print(\"traceObj:\",obj)\n",
    "    for key in obj:\n",
    "        print(key)\n",
    "\n",
    "def getNodeClass(node):\n",
    "    try:\n",
    "        return node[\"class\"]\n",
    "    except:\n",
    "        return None;\n",
    "\n",
    "def parseLeftUL(ul,childList):\n",
    "    #print(\"parseLeftUL:\",ul)\n",
    "    #traceChildren(ul.children)\n",
    "    \n",
    "    for child in ul.children:\n",
    "        aO=child.find(\"a\")\n",
    "        if aO==None:\n",
    "            print(child.string)\n",
    "            aObj={}\n",
    "            aObj[\"title\"]=child.string.strip()\n",
    "            childList.append(aObj)\n",
    "            continue\n",
    "        #print(\"aO:\",aO)\n",
    "        aObj={};\n",
    "        aObj[\"href\"]=aO[\"href\"];\n",
    "        aObj[\"title\"]=aO.string\n",
    "        childList.append(aObj)\n",
    "    \n",
    "def parseWikiLeft(leftPart):\n",
    "    #traceChildren(leftPart.children)\n",
    "    navList=[]\n",
    "    for child in leftPart.children:\n",
    "        #print(\"!!!\",type(child),child.name)\n",
    "        tChildClass=getNodeClass(child)\n",
    "        if child.name==\"ul\":\n",
    "            if tNavO:\n",
    "                parseLeftUL(child,tNavO[\"child\"])\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        if tChildClass!=None:\n",
    "            if \"sidehead\" in tChildClass:\n",
    "                #print(child)\n",
    "                if child.a:\n",
    "                    break\n",
    "                tNavO={};\n",
    "                tNavO[\"title\"]=child.string\n",
    "                if tNavO[\"title\"]!=None:\n",
    "                    tNavO[\"title\"]=tNavO[\"title\"].strip()\n",
    "                tNavO[\"child\"]=[]\n",
    "                navList.append(tNavO)\n",
    "        #traceObj(child)\n",
    "    #print(navList)\n",
    "    return navList\n",
    "\n",
    "def parseWikiText(textPart):\n",
    "    navList=[]\n",
    "    tNavO=None\n",
    "    for child in textPart.children:\n",
    "        #print(\"!!!\",type(child),child.name)\n",
    "        tChildClass=getNodeClass(child)\n",
    "        if child.name==\"ul\":\n",
    "            if tNavO:\n",
    "                parseLeftUL(child,tNavO[\"child\"])\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        if tChildClass!=None:\n",
    "            if \"vspace\" in tChildClass:\n",
    "                #print(child)\n",
    "                tNavO={};\n",
    "                tNavO[\"title\"]=child.string\n",
    "                if tNavO[\"title\"]!=None:\n",
    "                    tNavO[\"title\"]=tNavO[\"title\"].strip()\n",
    "                tNavO[\"child\"]=[]\n",
    "                navList.append(tNavO)\n",
    "        else:\n",
    "            if tNavO==None:\n",
    "                if child.name==\"p\" and child.string.strip()!=\"\":\n",
    "                    tNavO={};\n",
    "                    tNavO[\"title\"]=child.string\n",
    "                    if tNavO[\"title\"]!=None:\n",
    "                        tNavO[\"title\"]=tNavO[\"title\"].strip()\n",
    "                    tNavO[\"child\"]=[]\n",
    "                    navList.append(tNavO)\n",
    "                    \n",
    "        #traceObj(child)\n",
    "    #print(\"wikitext:\",navList)\n",
    "    return navList\n",
    "\n",
    "def parseWikiTitle(titlePart):\n",
    "    group=titlePart.find(None,\"pagegroup\")\n",
    "    print(\"group:\",group.a.string)\n",
    "    title=titlePart.find(None,\"pagetitle\")\n",
    "    print(\"title:\",title.string.strip())\n",
    "    infoO={};\n",
    "    infoO[\"group\"]=group.a.string.strip()\n",
    "    infoO[\"title\"]=title.string.strip()\n",
    "    return infoO\n",
    "    \n",
    "def getStructDataFromHtmlO(xmlO):\n",
    "    rstO={}\n",
    "    leftPart=xmlO.find(id=\"wikileft\")\n",
    "    \n",
    "    \n",
    "    rstO[\"Nav\"]=parseWikiLeft(leftPart)\n",
    "\n",
    "    wikiTitle=xmlO.find(id=\"wikititle\")\n",
    "    #print(wikiTitle)\n",
    "    rstO[\"Info\"]=parseWikiTitle(wikiTitle)\n",
    "\n",
    "    wikiText=xmlO.find(id=\"wikitext\")\n",
    "    #print(wikiText)\n",
    "    rstO[\"Content\"]=parseWikiText(wikiText)\n",
    "    \n",
    "    return rstO\n",
    " \n",
    "def workHtmPage(patePath,fileName):\n",
    "    xmlO=readXml(patePath)\n",
    "    dataO=getStructDataFromHtmlO(xmlO)\n",
    "    fw=open(\"website/\"+fileName+\".json\",\"w\",encoding=\"utf-8\")\n",
    "    json.dump(dataO,fw,ensure_ascii=False,indent=4)\n",
    "\n",
    "def getDirFiles(dirPath):\n",
    "    files=os.listdir(dirPath)\n",
    "    print(files)\n",
    "    for tfile in files:\n",
    "        tfile=dirPath+\"/\"+tfile\n",
    "        #print(\"isdir:\",os.path.isdir(tfile))\n",
    "        if os.path.isdir(tfile):\n",
    "            continue\n",
    "        #print(tfile)\n",
    "        bname=os.path.basename(os.path.realpath(tfile))\n",
    "       # print(bname)\n",
    "        names=bname.split(\".\")\n",
    "        names.pop()\n",
    "        names=names[0].split(\" _ \")\n",
    "        names.pop(0)\n",
    "        #print(names)\n",
    "        #print(\"_\".join(names))\n",
    "        workHtmPage(tfile,\"_\".join(names))\n",
    "#workHtmPage(\"wiki/OrzWiki _ 学习 _ 量化交易.htm\")\n",
    "\n",
    "getDirFiles(\"wiki\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

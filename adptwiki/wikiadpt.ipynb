{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OrzWiki _ Main _ HomePage.htm', 'OrzWiki _ Main _ HomePage_files', 'OrzWiki _ Other _ Ideas.htm', 'OrzWiki _ Other _ Ideas_files', 'OrzWiki _ SNS _ 推荐引擎.htm', 'OrzWiki _ SNS _ 推荐引擎_files', 'OrzWiki _ SNS _ 网站相关.htm', 'OrzWiki _ SNS _ 网站相关_files', 'OrzWiki _ 学习 _ AR.htm', 'OrzWiki _ 学习 _ AR_files', 'OrzWiki _ 学习 _ As3.htm', 'OrzWiki _ 学习 _ As3_files', 'OrzWiki _ 学习 _ IDE.htm', 'OrzWiki _ 学习 _ IDE_files', 'OrzWiki _ 学习 _ Js.html', 'OrzWiki _ 学习 _ Js_files', 'OrzWiki _ 学习 _ Python.htm', 'OrzWiki _ 学习 _ Python_files', 'OrzWiki _ 学习 _ TodoList.htm', 'OrzWiki _ 学习 _ TodoList_files', 'OrzWiki _ 学习 _ 产品Amp运营.htm', 'OrzWiki _ 学习 _ 产品Amp运营_files', 'OrzWiki _ 学习 _ 公开课forDear.htm', 'OrzWiki _ 学习 _ 公开课forDear_files', 'OrzWiki _ 学习 _ 动画相关.htm', 'OrzWiki _ 学习 _ 动画相关_files', 'OrzWiki _ 学习 _ 安全相关.htm', 'OrzWiki _ 学习 _ 安全相关_files', 'OrzWiki _ 学习 _ 开放平台们.htm', 'OrzWiki _ 学习 _ 开放平台们_files', 'OrzWiki _ 学习 _ 数据分析.htm', 'OrzWiki _ 学习 _ 数据分析_files', 'OrzWiki _ 学习 _ 算法.htm', 'OrzWiki _ 学习 _ 算法_files', 'OrzWiki _ 学习 _ 语法分析.htm', 'OrzWiki _ 学习 _ 语法分析_files', 'OrzWiki _ 学习 _ 调试工具.htm', 'OrzWiki _ 学习 _ 调试工具_files', 'OrzWiki _ 学习 _ 量化交易.htm', 'OrzWiki _ 学习 _ 量化交易.html', 'OrzWiki _ 学习 _ 量化交易_files', 'OrzWiki _ 学习 _ 项目管理工具.htm', 'OrzWiki _ 学习 _ 项目管理工具_files', 'OrzWiki _ 工具 _ Chrome.htm', 'OrzWiki _ 工具 _ Chrome_files', 'OrzWiki _ 工具 _ 导航导航.htm', 'OrzWiki _ 工具 _ 导航导航_files', 'OrzWiki _ 生活 _ 动漫.htm', 'OrzWiki _ 生活 _ 动漫_files', 'OrzWiki _ 生活 _ 域名.htm', 'OrzWiki _ 生活 _ 域名_files', 'OrzWiki _ 生活 _ 心理社会星座.htm', 'OrzWiki _ 生活 _ 心理社会星座_files', 'OrzWiki _ 生活 _ 电影.htm', 'OrzWiki _ 生活 _ 电影_files', 'OrzWiki _ 生活 _ 读书.htm', 'OrzWiki _ 生活 _ 读书_files', 'OrzWiki _ 生活 _ 追剧.htm', 'OrzWiki _ 生活 _ 追剧_files', 'OrzWiki _ 生活 _ 音乐.htm', 'OrzWiki _ 生活 _ 音乐_files']\n",
      "wiki/OrzWiki _ Main _ HomePage.htm\n",
      "OrzWiki _ Main _ HomePage.htm\n",
      "['Main', 'HomePage']\n",
      "Main_HomePage\n",
      "group: Main\n",
      "title: HomePage\n",
      "wiki/OrzWiki _ Other _ Ideas.htm\n",
      "OrzWiki _ Other _ Ideas.htm\n",
      "['Other', 'Ideas']\n",
      "Other_Ideas\n",
      "group: Other\n",
      "title: Ideas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 184 of the file D:\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wiki/OrzWiki _ SNS _ 推荐引擎.htm\n",
      "OrzWiki _ SNS _ 推荐引擎.htm\n",
      "['SNS', '推荐引擎']\n",
      "SNS_推荐引擎\n",
      "group: SNS\n",
      "title: 推荐引擎\n",
      "wiki/OrzWiki _ SNS _ 网站相关.htm\n",
      "OrzWiki _ SNS _ 网站相关.htm\n",
      "['SNS', '网站相关']\n",
      "SNS_网站相关\n",
      "group: SNS\n",
      "title: 网站相关\n",
      "wiki/OrzWiki _ 学习 _ AR.htm\n",
      "OrzWiki _ 学习 _ AR.htm\n",
      "['学习', 'AR']\n",
      "学习_AR\n",
      "group: 学习\n",
      "title: AR\n",
      "wiki/OrzWiki _ 学习 _ As3.htm\n",
      "OrzWiki _ 学习 _ As3.htm\n",
      "['学习', 'As3']\n",
      "学习_As3\n",
      "group: 学习\n",
      "title: As3\n",
      "wiki/OrzWiki _ 学习 _ IDE.htm\n",
      "OrzWiki _ 学习 _ IDE.htm\n",
      "['学习', 'IDE']\n",
      "学习_IDE\n",
      "group: 学习\n",
      "title: IDE\n",
      "wiki/OrzWiki _ 学习 _ Js.html\n",
      "OrzWiki _ 学习 _ Js.html\n",
      "['学习', 'Js']\n",
      "学习_Js\n",
      "group: 学习\n",
      "title: Js\n",
      "wiki/OrzWiki _ 学习 _ Python.htm\n",
      "OrzWiki _ 学习 _ Python.htm\n",
      "['学习', 'Python']\n",
      "学习_Python\n",
      "group: 学习\n",
      "title: Python\n",
      "wiki/OrzWiki _ 学习 _ TodoList.htm\n",
      "OrzWiki _ 学习 _ TodoList.htm\n",
      "['学习', 'TodoList']\n",
      "学习_TodoList\n",
      "group: 学习\n",
      "title: TodoList\n",
      "wiki/OrzWiki _ 学习 _ 产品Amp运营.htm\n",
      "OrzWiki _ 学习 _ 产品Amp运营.htm\n",
      "['学习', '产品Amp运营']\n",
      "学习_产品Amp运营\n",
      "group: 学习\n",
      "title: 产品Amp运营\n",
      "wiki/OrzWiki _ 学习 _ 公开课forDear.htm\n",
      "OrzWiki _ 学习 _ 公开课forDear.htm\n",
      "['学习', '公开课forDear']\n",
      "学习_公开课forDear\n",
      "group: 学习\n",
      "title: 公开课forDear\n",
      "wiki/OrzWiki _ 学习 _ 动画相关.htm\n",
      "OrzWiki _ 学习 _ 动画相关.htm\n",
      "['学习', '动画相关']\n",
      "学习_动画相关\n",
      "group: 学习\n",
      "title: 动画相关\n",
      "wiki/OrzWiki _ 学习 _ 安全相关.htm\n",
      "OrzWiki _ 学习 _ 安全相关.htm\n",
      "['学习', '安全相关']\n",
      "学习_安全相关\n",
      "group: 学习\n",
      "title: 安全相关\n",
      "wiki/OrzWiki _ 学习 _ 开放平台们.htm\n",
      "OrzWiki _ 学习 _ 开放平台们.htm\n",
      "['学习', '开放平台们']\n",
      "学习_开放平台们\n",
      "group: 学习\n",
      "title: 开放平台们\n",
      "wiki/OrzWiki _ 学习 _ 数据分析.htm\n",
      "OrzWiki _ 学习 _ 数据分析.htm\n",
      "['学习', '数据分析']\n",
      "学习_数据分析\n",
      "group: 学习\n",
      "title: 数据分析\n",
      "wiki/OrzWiki _ 学习 _ 算法.htm\n",
      "OrzWiki _ 学习 _ 算法.htm\n",
      "['学习', '算法']\n",
      "学习_算法\n",
      "group: 学习\n",
      "title: 算法\n",
      "wiki/OrzWiki _ 学习 _ 语法分析.htm\n",
      "OrzWiki _ 学习 _ 语法分析.htm\n",
      "['学习', '语法分析']\n",
      "学习_语法分析\n",
      "group: 学习\n",
      "title: 语法分析\n",
      "wiki/OrzWiki _ 学习 _ 调试工具.htm\n",
      "OrzWiki _ 学习 _ 调试工具.htm\n",
      "['学习', '调试工具']\n",
      "学习_调试工具\n",
      "group: 学习\n",
      "title: 调试工具\n",
      "wiki/OrzWiki _ 学习 _ 量化交易.htm\n",
      "OrzWiki _ 学习 _ 量化交易.htm\n",
      "['学习', '量化交易']\n",
      "学习_量化交易\n",
      "group: 学习\n",
      "title: 量化交易\n",
      "wiki/OrzWiki _ 学习 _ 量化交易.html\n",
      "OrzWiki _ 学习 _ 量化交易.html\n",
      "['学习', '量化交易']\n",
      "学习_量化交易\n",
      "group: 学习\n",
      "title: 量化交易\n",
      "wiki/OrzWiki _ 学习 _ 项目管理工具.htm\n",
      "OrzWiki _ 学习 _ 项目管理工具.htm\n",
      "['学习', '项目管理工具']\n",
      "学习_项目管理工具\n",
      "group: 学习\n",
      "title: 项目管理工具\n",
      "wiki/OrzWiki _ 工具 _ Chrome.htm\n",
      "OrzWiki _ 工具 _ Chrome.htm\n",
      "['工具', 'Chrome']\n",
      "工具_Chrome\n",
      "group: 工具\n",
      "title: Chrome\n",
      "wiki/OrzWiki _ 工具 _ 导航导航.htm\n",
      "OrzWiki _ 工具 _ 导航导航.htm\n",
      "['工具', '导航导航']\n",
      "工具_导航导航\n",
      "group: 工具\n",
      "title: 导航导航\n",
      "wiki/OrzWiki _ 生活 _ 动漫.htm\n",
      "OrzWiki _ 生活 _ 动漫.htm\n",
      "['生活', '动漫']\n",
      "生活_动漫\n",
      "group: 生活\n",
      "title: 动漫\n",
      "wiki/OrzWiki _ 生活 _ 域名.htm\n",
      "OrzWiki _ 生活 _ 域名.htm\n",
      "['生活', '域名']\n",
      "生活_域名\n",
      "group: 生活\n",
      "title: 域名\n",
      "wiki/OrzWiki _ 生活 _ 心理社会星座.htm\n",
      "OrzWiki _ 生活 _ 心理社会星座.htm\n",
      "['生活', '心理社会星座']\n",
      "生活_心理社会星座\n",
      "group: 生活\n",
      "title: 心理社会星座\n",
      "wiki/OrzWiki _ 生活 _ 电影.htm\n",
      "OrzWiki _ 生活 _ 电影.htm\n",
      "['生活', '电影']\n",
      "生活_电影\n",
      "group: 生活\n",
      "title: 电影\n",
      "wiki/OrzWiki _ 生活 _ 读书.htm\n",
      "OrzWiki _ 生活 _ 读书.htm\n",
      "['生活', '读书']\n",
      "生活_读书\n",
      "group: 生活\n",
      "title: 读书\n",
      "wiki/OrzWiki _ 生活 _ 追剧.htm\n",
      "OrzWiki _ 生活 _ 追剧.htm\n",
      "['生活', '追剧']\n",
      "生活_追剧\n",
      "group: 生活\n",
      "title: 追剧\n",
      "wiki/OrzWiki _ 生活 _ 音乐.htm\n",
      "OrzWiki _ 生活 _ 音乐.htm\n",
      "['生活', '音乐']\n",
      "生活_音乐\n",
      "group: 生活\n",
      "title: 音乐\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "\n",
    "def readXml(filepath):\n",
    "    return BeautifulSoup(open(filepath,encoding=\"utf8\"))\n",
    "\n",
    "def traceChildren(children):\n",
    "    for child in children:\n",
    "        print(\"~~~\",child)\n",
    "def traceObj(obj):\n",
    "    print(\"traceObj:\",obj)\n",
    "    for key in obj:\n",
    "        print(key)\n",
    "\n",
    "def getNodeClass(node):\n",
    "    try:\n",
    "        return node[\"class\"]\n",
    "    except:\n",
    "        return None;\n",
    "\n",
    "def parseLeftUL(ul,childList):\n",
    "    #print(\"parseLeftUL:\",ul)\n",
    "    #traceChildren(ul.children)\n",
    "    \n",
    "    for child in ul.children:\n",
    "        aO=child.find(\"a\")\n",
    "        if aO==None:\n",
    "            continue\n",
    "        #print(\"aO:\",aO)\n",
    "        aObj={};\n",
    "        aObj[\"href\"]=aO[\"href\"];\n",
    "        aObj[\"title\"]=aO.string\n",
    "        childList.append(aObj)\n",
    "    \n",
    "def parseWikiLeft(leftPart):\n",
    "    #traceChildren(leftPart.children)\n",
    "    navList=[]\n",
    "    for child in leftPart.children:\n",
    "        #print(\"!!!\",type(child),child.name)\n",
    "        tChildClass=getNodeClass(child)\n",
    "        if child.name==\"ul\":\n",
    "            if tNavO:\n",
    "                parseLeftUL(child,tNavO[\"child\"])\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        if tChildClass!=None:\n",
    "            if \"sidehead\" in tChildClass:\n",
    "                #print(child)\n",
    "                if child.a:\n",
    "                    break\n",
    "                tNavO={};\n",
    "                tNavO[\"title\"]=child.string\n",
    "                if tNavO[\"title\"]!=None:\n",
    "                    tNavO[\"title\"]=tNavO[\"title\"].strip()\n",
    "                tNavO[\"child\"]=[]\n",
    "                navList.append(tNavO)\n",
    "        #traceObj(child)\n",
    "    #print(navList)\n",
    "    return navList\n",
    "\n",
    "def parseWikiText(textPart):\n",
    "    navList=[]\n",
    "    tNavO=None\n",
    "    for child in textPart.children:\n",
    "        #print(\"!!!\",type(child),child.name)\n",
    "        tChildClass=getNodeClass(child)\n",
    "        if child.name==\"ul\":\n",
    "            if tNavO:\n",
    "                parseLeftUL(child,tNavO[\"child\"])\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        if tChildClass!=None:\n",
    "            if \"vspace\" in tChildClass:\n",
    "                #print(child)\n",
    "                tNavO={};\n",
    "                tNavO[\"title\"]=child.string\n",
    "                if tNavO[\"title\"]!=None:\n",
    "                    tNavO[\"title\"]=tNavO[\"title\"].strip()\n",
    "                tNavO[\"child\"]=[]\n",
    "                navList.append(tNavO)\n",
    "        #traceObj(child)\n",
    "    #print(\"wikitext:\",navList)\n",
    "    return navList\n",
    "\n",
    "def parseWikiTitle(titlePart):\n",
    "    group=titlePart.find(None,\"pagegroup\")\n",
    "    print(\"group:\",group.a.string)\n",
    "    title=titlePart.find(None,\"pagetitle\")\n",
    "    print(\"title:\",title.string.strip())\n",
    "    infoO={};\n",
    "    infoO[\"group\"]=group.a.string.strip()\n",
    "    infoO[\"title\"]=title.string.strip()\n",
    "    return infoO\n",
    "    \n",
    "def getStructDataFromHtmlO(xmlO):\n",
    "    rstO={}\n",
    "    leftPart=xmlO.find(id=\"wikileft\")\n",
    "    \n",
    "    \n",
    "    rstO[\"Nav\"]=parseWikiLeft(leftPart)\n",
    "\n",
    "    wikiTitle=xmlO.find(id=\"wikititle\")\n",
    "    #print(wikiTitle)\n",
    "    rstO[\"Info\"]=parseWikiTitle(wikiTitle)\n",
    "\n",
    "    wikiText=xmlO.find(id=\"wikitext\")\n",
    "    #print(wikiText)\n",
    "    rstO[\"Content\"]=parseWikiText(wikiText)\n",
    "    \n",
    "    return rstO\n",
    " \n",
    "def workHtmPage(patePath,fileName):\n",
    "    xmlO=readXml(patePath)\n",
    "    dataO=getStructDataFromHtmlO(xmlO)\n",
    "    fw=open(\"website/\"+fileName+\".json\",\"w\",encoding=\"utf-8\")\n",
    "    json.dump(dataO,fw,ensure_ascii=False,indent=4)\n",
    "\n",
    "def getDirFiles(dirPath):\n",
    "    files=os.listdir(dirPath)\n",
    "    print(files)\n",
    "    for tfile in files:\n",
    "        tfile=dirPath+\"/\"+tfile\n",
    "        #print(\"isdir:\",os.path.isdir(tfile))\n",
    "        if os.path.isdir(tfile):\n",
    "            continue\n",
    "        print(tfile)\n",
    "        bname=os.path.basename(os.path.realpath(tfile))\n",
    "        print(bname)\n",
    "        names=bname.split(\".\")\n",
    "        names.pop()\n",
    "        names=names[0].split(\" _ \")\n",
    "        names.pop(0)\n",
    "        print(names)\n",
    "        print(\"_\".join(names))\n",
    "        workHtmPage(tfile,\"_\".join(names))\n",
    "#workHtmPage(\"wiki/OrzWiki _ 学习 _ 量化交易.htm\")\n",
    "\n",
    "getDirFiles(\"wiki\")\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
